{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unitree G1 Humanoid Robot SDK Tutorial\n",
    "\n",
    "This notebook provides a comprehensive guide to using the Unitree SDK2 Python interface for controlling the G1 humanoid robot.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup & Installation](#setup)\n",
    "2. [Audio Control](#audio)\n",
    "3. [High-Level Control - Locomotion](#locomotion)\n",
    "4. [High-Level Control - Arm Actions](#arm-actions)\n",
    "5. [High-Level Control - Arm SDK (5-DOF)](#arm5)\n",
    "6. [High-Level Control - Arm SDK (7-DOF)](#arm7)\n",
    "7. [Low-Level Motor Control](#low-level)\n",
    "8. [Data Visualization](#visualization)\n",
    "\n",
    "---\n",
    "\n",
    "## Resources & Documentation\n",
    "\n",
    "- **GitHub Repository**: [unitree_sdk2_python](https://github.com/unitreerobotics/unitree_sdk2_python)\n",
    "- **Official Documentation**: [Unitree Developer Portal](https://support.unitree.com/home/en/developer)\n",
    "- **Robot Models**: G1 / H1-2 (uses `unitree_hg` IDL)\n",
    "- **Python Version**: >= 3.8\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 1. Setup & Installation\n",
    "\n",
    "### Prerequisites\n",
    "- Python >= 3.8\n",
    "- Network connection to the robot\n",
    "- Network interface name (e.g., `eth0`, `enp2s0`, `wlan0`)\n",
    "\n",
    "### Installation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv package manager (fast pip replacement)\n",
    "!python -m pip install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create virtual environment with uv\n",
    "!uv venv .venv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate Virtual Environment\n",
    "\n",
    "**Windows:**\n",
    "```bash\n",
    ".venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "**Linux/macOS:**\n",
    "```bash\n",
    "source .venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core dependencies\n",
    "!uv pip install cyclonedds==0.10.2 numpy opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Unitree SDK2 Python (editable mode)\n",
    "!uv pip install -e unitree_sdk2_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages for data analysis and visualization\n",
    "!uv pip install matplotlib pandas scipy seaborn pyrealsense2 open3d jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting: CycloneDDS Installation\n",
    "\n",
    "If you encounter errors about `CYCLONEDDS_HOME` not being found, you may need to build CycloneDDS from source:\n",
    "\n",
    "```bash\n",
    "cd ~\n",
    "git clone https://github.com/eclipse-cyclonedds/cyclonedds -b releases/0.10.x\n",
    "cd cyclonedds && mkdir build install && cd build\n",
    "cmake .. -DCMAKE_INSTALL_PREFIX=../install\n",
    "cmake --build . --target install\n",
    "\n",
    "# Set environment variable\n",
    "export CYCLONEDDS_HOME=\"~/cyclonedds/install\"\n",
    "\n",
    "# Then retry SDK installation\n",
    "cd ~/unitree_sdk2_python\n",
    "pip3 install -e .\n",
    "```\n",
    "\n",
    "For details, see: https://pypi.org/project/cyclonedds/#installing-with-pre-built-binaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Configuration\n",
    "\n",
    "Before running examples, configure network connection to the robot. See:\n",
    "https://support.unitree.com/home/en/developer/Quick_start\n",
    "\n",
    "**Find your network interface:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux/macOS\n",
    "!ip link show\n",
    "# or\n",
    "!ifconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "!ipconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your network interface name\n",
    "NETWORK_INTERFACE = \"eth0\"  # Change this to your actual interface (e.g., enp2s0, wlan0, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Unitree SDK imports\n",
    "from unitree_sdk2py.core.channel import ChannelSubscriber, ChannelPublisher, ChannelFactoryInitialize\n",
    "from unitree_sdk2py.idl.unitree_hg.msg.dds_ import LowCmd_, LowState_\n",
    "from unitree_sdk2py.utils.crc import CRC\n",
    "from unitree_sdk2py.utils.thread import RecurrentThread\n",
    "\n",
    "# G1-specific imports\n",
    "from unitree_sdk2py.g1.audio.g1_audio_client import AudioClient\n",
    "from unitree_sdk2py.g1.loco.g1_loco_client import LocoClient\n",
    "from unitree_sdk2py.g1.arm.g1_arm_action_client import G1ArmActionClient, action_map\n",
    "from unitree_sdk2py.comm.motion_switcher.motion_switcher_client import MotionSwitcherClient\n",
    "\n",
    "print(\"‚úì All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='audio'></a>\n",
    "## 2. Audio Control\n",
    "\n",
    "Control the robot's audio output, text-to-speech, LED lights, and volume.\n",
    "\n",
    "### Features:\n",
    "- Volume control\n",
    "- Text-to-Speech (TTS) in Chinese\n",
    "- LED light control (RGB)\n",
    "- WAV file playback (16kHz mono)\n",
    "\n",
    "**Reference**: `example/g1/audio/g1_audio_client_example.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic Audio Control Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DDS communication\n",
    "ChannelFactoryInitialize(0, NETWORK_INTERFACE)\n",
    "\n",
    "# Create audio client\n",
    "audio_client = AudioClient()\n",
    "audio_client.SetTimeout(10.0)\n",
    "audio_client.Init()\n",
    "\n",
    "# Create locomotion client (for wave hand demo)\n",
    "sport_client = LocoClient()\n",
    "sport_client.SetTimeout(10.0)\n",
    "sport_client.Init()\n",
    "\n",
    "print(\"‚úì Audio client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current volume\n",
    "current_volume = audio_client.GetVolume()\n",
    "print(f\"Current volume: {current_volume}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set volume (0-100)\n",
    "audio_client.SetVolume(85)\n",
    "print(f\"Volume set to: {audio_client.GetVolume()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wave hand gesture\n",
    "sport_client.WaveHand()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-to-Speech (Chinese)\n",
    "audio_client.TtsMaker(\"Â§ßÂÆ∂Â•Ω!ÊàëÊòØÂÆáÊ†ëÁßëÊäÄ‰∫∫ÂΩ¢Êú∫Âô®‰∫∫„ÄÇ\", 0)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 LED Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LED Control - Red, Green, Blue (RGB values 0-255)\n",
    "audio_client.TtsMaker(\"Á∫¢Ëâ≤\", 0)\n",
    "audio_client.LedControl(255, 0, 0)  # Red\n",
    "time.sleep(1)\n",
    "\n",
    "audio_client.TtsMaker(\"ÁªøËâ≤\", 0)\n",
    "audio_client.LedControl(0, 255, 0)  # Green\n",
    "time.sleep(1)\n",
    "\n",
    "audio_client.TtsMaker(\"ËìùËâ≤\", 0)\n",
    "audio_client.LedControl(0, 0, 255)  # Blue\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Play WAV File\n",
    "\n",
    "**Requirements**: 16kHz, Mono, PCM format\n",
    "\n",
    "**Reference**: `example/g1/audio/g1_audio_client_play_wav.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example WAV playback (requires wav.py helper functions)\n",
    "# Uncomment and modify with your WAV file path\n",
    "\n",
    "# from wav import read_wav, play_pcm_stream\n",
    "# \n",
    "# wav_path = \"path/to/your/audio.wav\"\n",
    "# pcm_list, sample_rate, num_channels, is_ok = read_wav(wav_path)\n",
    "# \n",
    "# if is_ok and sample_rate == 16000 and num_channels == 1:\n",
    "#     play_pcm_stream(audio_client, pcm_list, \"example\")\n",
    "#     time.sleep(5)\n",
    "#     audio_client.PlayStop(\"example\")\n",
    "# else:\n",
    "#     print(\"Error: WAV must be 16kHz mono format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='locomotion'></a>\n",
    "## 3. High-Level Control - Locomotion\n",
    "\n",
    "Control robot movement, posture, and special motions.\n",
    "\n",
    "### Available Commands:\n",
    "- **Basic**: Damp, Stand Up/Down, Squat\n",
    "- **Movement**: Forward, Lateral, Rotation\n",
    "- **Posture**: Low Stand, High Stand, Zero Torque\n",
    "- **Special**: Wave Hand, Shake Hand\n",
    "\n",
    "**Reference**: `example/g1/high_level/g1_loco_client_example.py`\n",
    "\n",
    "**Documentation**: https://support.unitree.com/home/en/developer/sports_services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize locomotion client\n",
    "ChannelFactoryInitialize(0, NETWORK_INTERFACE)\n",
    "\n",
    "sport_client = LocoClient()\n",
    "sport_client.SetTimeout(10.0)\n",
    "sport_client.Init()\n",
    "\n",
    "print(\"‚úì Locomotion client initialized\")\n",
    "print(\"‚ö†Ô∏è  WARNING: Ensure clear space around the robot!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Available Motion Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define available test options\n",
    "@dataclass\n",
    "class TestOption:\n",
    "    name: str\n",
    "    id: int\n",
    "    description: str\n",
    "\n",
    "locomotion_options = [\n",
    "    TestOption(\"damp\", 0, \"Damping mode - motors relaxed\"),\n",
    "    TestOption(\"Squat2StandUp\", 1, \"Stand up from squatting position\"),\n",
    "    TestOption(\"StandUp2Squat\", 2, \"Squat down from standing\"),\n",
    "    TestOption(\"move forward\", 3, \"Move forward at 0.3 m/s\"),\n",
    "    TestOption(\"move lateral\", 4, \"Move sideways at 0.3 m/s\"),\n",
    "    TestOption(\"move rotate\", 5, \"Rotate at 0.3 rad/s\"),\n",
    "    TestOption(\"low stand\", 6, \"Lower standing posture\"),\n",
    "    TestOption(\"high stand\", 7, \"Higher standing posture\"),\n",
    "    TestOption(\"zero torque\", 8, \"Zero torque mode\"),\n",
    "    TestOption(\"wave hand1\", 9, \"Wave hand (no turn)\"),\n",
    "    TestOption(\"wave hand2\", 10, \"Wave hand with turn around\"),\n",
    "    TestOption(\"shake hand\", 11, \"Shake hand gesture\"),\n",
    "    TestOption(\"Lie2StandUp\", 12, \"Stand up from lying position\"),\n",
    "]\n",
    "\n",
    "# Display options\n",
    "print(\"Available Locomotion Commands:\\n\")\n",
    "for opt in locomotion_options:\n",
    "    print(f\"  [{opt.id:2d}] {opt.name:20s} - {opt.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Execute Locomotion Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Damping mode\n",
    "sport_client.Damp()\n",
    "print(\"Executed: Damp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Stand up from squat\n",
    "sport_client.Damp()\n",
    "time.sleep(0.5)\n",
    "sport_client.Squat2StandUp()\n",
    "print(\"Executed: Squat to Stand Up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Move forward\n",
    "sport_client.Move(0.3, 0, 0)  # (vx, vy, vyaw)\n",
    "print(\"Executed: Move Forward (0.3 m/s)\")\n",
    "time.sleep(2)\n",
    "sport_client.Move(0, 0, 0)  # Stop\n",
    "print(\"Stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Wave hand without turning\n",
    "sport_client.WaveHand()\n",
    "print(\"Executed: Wave Hand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Wave hand with turn around\n",
    "sport_client.WaveHand(True)\n",
    "print(\"Executed: Wave Hand with Turn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Shake hand\n",
    "sport_client.ShakeHand()\n",
    "time.sleep(3)\n",
    "sport_client.ShakeHand()  # Execute twice as per example\n",
    "print(\"Executed: Shake Hand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='arm-actions'></a>\n",
    "## 4. High-Level Control - Arm Actions\n",
    "\n",
    "Pre-programmed arm gestures and social interactions.\n",
    "\n",
    "### Available Actions:\n",
    "- Social gestures (wave, shake hand, high five, hug)\n",
    "- Expressive actions (heart, kiss, clap)\n",
    "- Functional poses (hands up, reject)\n",
    "\n",
    "**Reference**: `example/g1/high_level/g1_arm_action_example.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arm action client\n",
    "ChannelFactoryInitialize(0, NETWORK_INTERFACE)\n",
    "\n",
    "armAction_client = G1ArmActionClient()\n",
    "armAction_client.SetTimeout(10.0)\n",
    "armAction_client.Init()\n",
    "\n",
    "print(\"‚úì Arm action client initialized\")\n",
    "print(\"‚ö†Ô∏è  WARNING: Ensure clear space around the robot!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Available Arm Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_action_options = [\n",
    "    TestOption(\"release arm\", 0, \"Release arm control\"),\n",
    "    TestOption(\"shake hand\", 1, \"Handshake gesture\"),\n",
    "    TestOption(\"high five\", 2, \"High five gesture\"),\n",
    "    TestOption(\"hug\", 3, \"Hug gesture\"),\n",
    "    TestOption(\"high wave\", 4, \"High wave gesture\"),\n",
    "    TestOption(\"clap\", 5, \"Clapping motion\"),\n",
    "    TestOption(\"face wave\", 6, \"Wave near face\"),\n",
    "    TestOption(\"left kiss\", 7, \"Blow kiss (left hand)\"),\n",
    "    TestOption(\"heart\", 8, \"Heart shape with both hands\"),\n",
    "    TestOption(\"right heart\", 9, \"Heart shape (right emphasis)\"),\n",
    "    TestOption(\"hands up\", 10, \"Raise both hands\"),\n",
    "    TestOption(\"x-ray\", 11, \"X-ray pose (crossed arms)\"),\n",
    "    TestOption(\"right hand up\", 12, \"Raise right hand\"),\n",
    "    TestOption(\"reject\", 13, \"Rejection gesture\"),\n",
    "    TestOption(\"right kiss\", 14, \"Blow kiss (right hand)\"),\n",
    "    TestOption(\"two-hand kiss\", 15, \"Blow kiss (both hands)\"),\n",
    "]\n",
    "\n",
    "# Display options\n",
    "print(\"Available Arm Actions:\\n\")\n",
    "for opt in arm_action_options:\n",
    "    print(f\"  [{opt.id:2d}] {opt.name:20s} - {opt.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Execute Arm Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Shake hand\n",
    "armAction_client.ExecuteAction(action_map.get(\"shake hand\"))\n",
    "time.sleep(2)\n",
    "armAction_client.ExecuteAction(action_map.get(\"release arm\"))\n",
    "print(\"Executed: Shake Hand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: High five\n",
    "armAction_client.ExecuteAction(action_map.get(\"high five\"))\n",
    "time.sleep(2)\n",
    "armAction_client.ExecuteAction(action_map.get(\"release arm\"))\n",
    "print(\"Executed: High Five\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Heart gesture\n",
    "armAction_client.ExecuteAction(action_map.get(\"heart\"))\n",
    "time.sleep(2)\n",
    "armAction_client.ExecuteAction(action_map.get(\"release arm\"))\n",
    "print(\"Executed: Heart Gesture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Clap\n",
    "armAction_client.ExecuteAction(action_map.get(\"clap\"))\n",
    "time.sleep(3)\n",
    "print(\"Executed: Clap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='arm5'></a>\n",
    "## 5. High-Level Control - Arm SDK (5-DOF)\n",
    "\n",
    "Direct control of 5-DOF arm joints (shoulder pitch/roll/yaw, elbow, wrist roll).\n",
    "\n",
    "**Reference**: `example/g1/high_level/g1_arm5_sdk_dds_example.py`\n",
    "\n",
    "**Note**: For G1 23-DOF variant (excludes wrist pitch/yaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Arm5 Joint Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-DOF Arm joints (per arm):\n",
    "# - LeftShoulderPitch, LeftShoulderRoll, LeftShoulderYaw\n",
    "# - LeftElbow, LeftWristRoll\n",
    "# - RightShoulderPitch, RightShoulderRoll, RightShoulderYaw\n",
    "# - RightElbow, RightWristRoll\n",
    "# + WaistYaw, WaistRoll, WaistPitch\n",
    "\n",
    "print(\"\"\"5-DOF Arm Control:\n",
    "- Target Position: Arms raised to sides (T-pose variation)\n",
    "- Control Parameters: kp=60.0, kd=1.5\n",
    "- Duration: 3 stages (3s each)\n",
    "  1. Move to zero posture\n",
    "  2. Lift arms up\n",
    "  3. Return to zero\n",
    "  4. Release arm SDK\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example requires running as a standalone script\n",
    "# See: unitree_sdk2_python/example/g1/high_level/g1_arm5_sdk_dds_example.py\n",
    "\n",
    "# To run:\n",
    "# !python unitree_sdk2_python/example/g1/high_level/g1_arm5_sdk_dds_example.py {NETWORK_INTERFACE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='arm7'></a>\n",
    "## 6. High-Level Control - Arm SDK (7-DOF)\n",
    "\n",
    "Direct control of 7-DOF arm joints (includes wrist pitch and yaw).\n",
    "\n",
    "**Reference**: `example/g1/high_level/g1_arm7_sdk_dds_example.py`\n",
    "\n",
    "**Note**: For G1 29-DOF variant (includes wrist pitch/yaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Arm7 Joint Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-DOF Arm joints (per arm):\n",
    "# - LeftShoulderPitch, LeftShoulderRoll, LeftShoulderYaw\n",
    "# - LeftElbow\n",
    "# - LeftWristRoll, LeftWristPitch, LeftWristYaw\n",
    "# (Same for right arm)\n",
    "# + WaistYaw, WaistRoll, WaistPitch\n",
    "\n",
    "print(\"\"\"7-DOF Arm Control:\n",
    "- Additional wrist pitch/yaw control\n",
    "- More dexterous manipulation capability\n",
    "- Same control flow as 5-DOF variant\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example requires running as a standalone script\n",
    "# See: unitree_sdk2_python/example/g1/high_level/g1_arm7_sdk_dds_example.py\n",
    "\n",
    "# To run:\n",
    "# !python unitree_sdk2_python/example/g1/high_level/g1_arm7_sdk_dds_example.py {NETWORK_INTERFACE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='low-level'></a>\n",
    "## 7. Low-Level Motor Control\n",
    "\n",
    "Direct motor control with position, velocity, and torque commands.\n",
    "\n",
    "### Features:\n",
    "- 29 motor control (legs, waist, arms)\n",
    "- PD control (Kp, Kd gains)\n",
    "- Two ankle control modes: PR (Pitch/Roll) and AB (A/B joints)\n",
    "- IMU state feedback\n",
    "\n",
    "**Reference**: `example/g1/low_level/g1_low_level_example.py`\n",
    "\n",
    "**Documentation**: https://support.unitree.com/home/en/developer/Basic_services\n",
    "\n",
    "‚ö†Ô∏è **WARNING**: Low-level control bypasses safety checks. Use with caution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 G1 Joint Index Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G1JointIndex:\n",
    "    # Left leg\n",
    "    LeftHipPitch = 0\n",
    "    LeftHipRoll = 1\n",
    "    LeftHipYaw = 2\n",
    "    LeftKnee = 3\n",
    "    LeftAnklePitch = 4  # Also LeftAnkleB\n",
    "    LeftAnkleRoll = 5   # Also LeftAnkleA\n",
    "    \n",
    "    # Right leg\n",
    "    RightHipPitch = 6\n",
    "    RightHipRoll = 7\n",
    "    RightHipYaw = 8\n",
    "    RightKnee = 9\n",
    "    RightAnklePitch = 10  # Also RightAnkleB\n",
    "    RightAnkleRoll = 11   # Also RightAnkleA\n",
    "    \n",
    "    # Waist (INVALID for locked waist on 23/29 DOF)\n",
    "    WaistYaw = 12\n",
    "    WaistRoll = 13    # WaistA\n",
    "    WaistPitch = 14   # WaistB\n",
    "    \n",
    "    # Left arm\n",
    "    LeftShoulderPitch = 15\n",
    "    LeftShoulderRoll = 16\n",
    "    LeftShoulderYaw = 17\n",
    "    LeftElbow = 18\n",
    "    LeftWristRoll = 19\n",
    "    LeftWristPitch = 20   # INVALID for 23 DOF\n",
    "    LeftWristYaw = 21     # INVALID for 23 DOF\n",
    "    \n",
    "    # Right arm\n",
    "    RightShoulderPitch = 22\n",
    "    RightShoulderRoll = 23\n",
    "    RightShoulderYaw = 24\n",
    "    RightElbow = 25\n",
    "    RightWristRoll = 26\n",
    "    RightWristPitch = 27  # INVALID for 23 DOF\n",
    "    RightWristYaw = 28    # INVALID for 23 DOF\n",
    "\n",
    "print(\"G1 has 29 motors total (23-DOF or 29-DOF variants)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Default Control Gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Kp (Position gains)\n",
    "Kp = [\n",
    "    60, 60, 60, 100, 40, 40,      # Left leg\n",
    "    60, 60, 60, 100, 40, 40,      # Right leg\n",
    "    60, 40, 40,                   # Waist\n",
    "    40, 40, 40, 40, 40, 40, 40,   # Left arm\n",
    "    40, 40, 40, 40, 40, 40, 40    # Right arm\n",
    "]\n",
    "\n",
    "# Default Kd (Velocity gains)\n",
    "Kd = [\n",
    "    1, 1, 1, 2, 1, 1,       # Left leg\n",
    "    1, 1, 1, 2, 1, 1,       # Right leg\n",
    "    1, 1, 1,                # Waist\n",
    "    1, 1, 1, 1, 1, 1, 1,    # Left arm\n",
    "    1, 1, 1, 1, 1, 1, 1     # Right arm\n",
    "]\n",
    "\n",
    "print(f\"Kp gains: {len(Kp)} motors\")\n",
    "print(f\"Kd gains: {len(Kd)} motors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Low-Level Control Example\n",
    "\n",
    "The example demonstrates:\n",
    "1. **Stage 1** (0-3s): Move to zero posture\n",
    "2. **Stage 2** (3-6s): Swing ankles using PR mode (Pitch/Roll)\n",
    "3. **Stage 3** (6s+): Swing ankles using AB mode (A/B joints) + wrist rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example requires running as a standalone script with background threads\n",
    "# See: unitree_sdk2_python/example/g1/low_level/g1_low_level_example.py\n",
    "\n",
    "# To run:\n",
    "# !python unitree_sdk2_python/example/g1/low_level/g1_low_level_example.py {NETWORK_INTERFACE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Reading Low-Level State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Subscribe to low-level state for monitoring\n",
    "# This provides IMU data, motor states, battery voltage, etc.\n",
    "\n",
    "state_data = []\n",
    "\n",
    "def LowStateHandler(msg: LowState_):\n",
    "    \"\"\"Callback for low-level state updates\"\"\"\n",
    "    state_data.append({\n",
    "        'timestamp': time.time(),\n",
    "        'imu_rpy': msg.imu_state.rpy,\n",
    "        'battery_voltage': msg.power_v,\n",
    "        # Add more fields as needed\n",
    "    })\n",
    "\n",
    "# Initialize subscriber\n",
    "# ChannelFactoryInitialize(0, NETWORK_INTERFACE)\n",
    "# lowstate_subscriber = ChannelSubscriber(\"rt/lowstate\", LowState_)\n",
    "# lowstate_subscriber.Init(LowStateHandler, 10)\n",
    "\n",
    "print(\"Low-level state subscriber ready (uncomment to activate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='visualization'></a>\n",
    "## 8. Data Visualization\n",
    "\n",
    "Visualize robot sensor data and telemetry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 IMU Data Visualization (Placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for IMU data plotting\n",
    "# Requires collecting state_data from low-level state subscriber\n",
    "\n",
    "# Generate example data\n",
    "t = np.linspace(0, 10, 100)\n",
    "roll = 0.1 * np.sin(2 * np.pi * 0.5 * t) + np.random.normal(0, 0.01, len(t))\n",
    "pitch = 0.05 * np.cos(2 * np.pi * 0.3 * t) + np.random.normal(0, 0.01, len(t))\n",
    "yaw = 0.15 * np.sin(2 * np.pi * 0.2 * t) + np.random.normal(0, 0.01, len(t))\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8))\n",
    "axes[0].plot(t, roll, 'r-', label='Roll')\n",
    "axes[0].set_ylabel('Roll (rad)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(t, pitch, 'g-', label='Pitch')\n",
    "axes[1].set_ylabel('Pitch (rad)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[2].plot(t, yaw, 'b-', label='Yaw')\n",
    "axes[2].set_ylabel('Yaw (rad)')\n",
    "axes[2].set_xlabel('Time (s)')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.suptitle('IMU Orientation (Roll-Pitch-Yaw)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä IMU Data Visualization (Example Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Joint Angle Visualization (Placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for joint angle trajectories\n",
    "\n",
    "joint_names = ['Hip Pitch', 'Hip Roll', 'Hip Yaw', 'Knee', 'Ankle Pitch', 'Ankle Roll']\n",
    "num_joints = len(joint_names)\n",
    "t = np.linspace(0, 5, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for i, joint in enumerate(joint_names):\n",
    "    # Generate example sinusoidal trajectories\n",
    "    phase = i * np.pi / 6\n",
    "    trajectory = 0.3 * np.sin(2 * np.pi * 0.5 * t + phase)\n",
    "    ax.plot(t, trajectory, label=joint, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Time (s)', fontsize=12)\n",
    "ax.set_ylabel('Joint Angle (rad)', fontsize=12)\n",
    "ax.set_title('Left Leg Joint Angles', fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Joint Angle Visualization (Example Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Battery & Power Statistics (Placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for battery voltage and power consumption\n",
    "\n",
    "t = np.linspace(0, 60, 300)  # 1 minute of data\n",
    "battery_voltage = 48.0 - 0.1 * (t / 60) + np.random.normal(0, 0.05, len(t))\n",
    "current_draw = 5.0 + 2.0 * np.sin(2 * np.pi * 0.2 * t) + np.random.normal(0, 0.2, len(t))\n",
    "power = battery_voltage * current_draw\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 8))\n",
    "\n",
    "ax1.plot(t, battery_voltage, 'b-', linewidth=1.5)\n",
    "ax1.set_ylabel('Voltage (V)', fontsize=11)\n",
    "ax1.set_title('Battery Voltage', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=44.0, color='r', linestyle='--', label='Low Battery Threshold')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(t, current_draw, 'g-', linewidth=1.5)\n",
    "ax2.set_ylabel('Current (A)', fontsize=11)\n",
    "ax2.set_title('Current Draw', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3.plot(t, power, 'orange', linewidth=1.5)\n",
    "ax3.set_xlabel('Time (s)', fontsize=11)\n",
    "ax3.set_ylabel('Power (W)', fontsize=11)\n",
    "ax3.set_title('Power Consumption', fontsize=12)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Battery & Power Statistics (Example Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 RealSense Depth Map Visualization (Placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for RealSense depth camera visualization\n",
    "# Requires pyrealsense2 library and actual camera data\n",
    "\n",
    "# Generate synthetic depth map\n",
    "depth_map = np.random.rand(480, 640) * 5.0  # Random depth 0-5 meters\n",
    "\n",
    "# Add some structure (object in center)\n",
    "y, x = np.ogrid[-240:240, -320:320]\n",
    "mask = x**2 + y**2 <= 100**2\n",
    "depth_map[mask] = 2.0  # Object at 2m\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "im = ax.imshow(depth_map, cmap='jet', vmin=0, vmax=5)\n",
    "ax.set_title('RealSense Depth Map (Synthetic)', fontsize=14)\n",
    "ax.set_xlabel('X (pixels)')\n",
    "ax.set_ylabel('Y (pixels)')\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Depth (m)', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä RealSense Depth Map (Synthetic Data)\")\n",
    "print(\"To use real RealSense data, install pyrealsense2 and capture frames from camera\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 LiDAR Point Cloud Visualization (Placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for LiDAR point cloud visualization\n",
    "# For full 3D visualization, use open3d library\n",
    "\n",
    "# Generate synthetic LiDAR scan (2D slice)\n",
    "num_points = 360\n",
    "angles = np.linspace(0, 2*np.pi, num_points)\n",
    "ranges = 3.0 + 0.5*np.sin(5*angles) + np.random.normal(0, 0.1, num_points)\n",
    "\n",
    "# Convert to Cartesian coordinates\n",
    "x = ranges * np.cos(angles)\n",
    "y = ranges * np.sin(angles)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))\n",
    "ax.scatter(angles, ranges, c=ranges, cmap='viridis', s=10)\n",
    "ax.set_title('LiDAR Scan (2D Slice)', fontsize=14, pad=20)\n",
    "ax.set_ylim(0, 5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cartesian plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "scatter = ax.scatter(x, y, c=ranges, cmap='viridis', s=10)\n",
    "ax.scatter(0, 0, c='red', s=100, marker='x', label='Robot')\n",
    "ax.set_xlabel('X (m)')\n",
    "ax.set_ylabel('Y (m)')\n",
    "ax.set_title('LiDAR Point Cloud (Top-Down View)', fontsize=14)\n",
    "ax.axis('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Range (m)', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä LiDAR Point Cloud (Synthetic Data)\")\n",
    "print(\"For 3D visualization with real data, use open3d library\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This notebook covered:\n",
    "\n",
    "1. **SDK Installation** - Setting up unitree_sdk2_python with dependencies\n",
    "2. **Audio Control** - TTS, volume, LED control, WAV playback\n",
    "3. **Locomotion** - Walking, postures, special motions\n",
    "4. **Arm Actions** - Pre-programmed gestures and social interactions\n",
    "5. **Arm SDK** - Direct 5-DOF and 7-DOF arm control\n",
    "6. **Low-Level Control** - Direct motor control with PD gains\n",
    "7. **Visualization** - IMU, joints, battery, depth maps, LiDAR\n",
    "\n",
    "### Next Steps:\n",
    "- Integrate with ROS for navigation and planning\n",
    "- Implement computer vision pipelines (OpenCV, RealSense)\n",
    "- Develop custom behaviors and state machines\n",
    "- Create teleoperation interfaces\n",
    "- Add reinforcement learning for advanced control\n",
    "\n",
    "### Additional Resources:\n",
    "- [Unitree Developer Portal](https://support.unitree.com/home/en/developer)\n",
    "- [SDK GitHub Issues](https://github.com/unitreerobotics/unitree_sdk2_python/issues)\n",
    "- [Community Forum](https://www.unitree.com/community/)\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö†Ô∏è Safety Reminders:**\n",
    "- Always ensure clear space around the robot\n",
    "- Start with damping mode before executing motions\n",
    "- Use emergency stop if available\n",
    "- Monitor battery levels\n",
    "- Test in simulation first when possible\n",
    "\n",
    "---\n",
    "\n",
    "*Created with Unitree SDK2 Python v1.0.1*  \n",
    "*For G1/H1-2 humanoid robots*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
