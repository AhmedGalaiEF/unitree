{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag 3: Navigation & Umgebungserkennung\n",
    "## Unitree G1 Humanoid Roboter Academy\n",
    "\n",
    "### Agenda Tag 3:\n",
    "1. SLAM (Simultaneous Localization and Mapping)\n",
    "2. LiDAR-Integration (Livox MID-360)\n",
    "3. Mapping & Lokalisierung\n",
    "4. Globale Pfadplanung (A*, RRT)\n",
    "5. Lokale Hindernisvermeidung\n",
    "6. Workshop: Navigationsaufgabe mit Hindernisfeld\n",
    "7. Sensorintegration (RealSense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. SLAM Grundlagen\n",
    "\n",
    "### 1.1 Was ist SLAM?\n",
    "\n",
    "**SLAM = Simultaneous Localization and Mapping**\n",
    "\n",
    "**Problem:**\n",
    "- Roboter in unbekannter Umgebung\n",
    "- Keine Karte verfügbar\n",
    "- Keine genaue Position bekannt\n",
    "\n",
    "**Lösung:**\n",
    "- **Gleichzeitig:**\n",
    "  - Karte der Umgebung erstellen (Mapping)\n",
    "  - Eigene Position in der Karte bestimmen (Localization)\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────┐\n",
    "│  Sensor Data (LiDAR, RGB-D)        │\n",
    "└──────────────┬─────────────────────┘\n",
    "               │\n",
    "┌──────────────▼─────────────────────┐\n",
    "│  SLAM Algorithm                    │\n",
    "│  - Feature Extraction              │\n",
    "│  - Data Association                │\n",
    "│  - State Estimation                │\n",
    "│  - Map Update                      │\n",
    "└──────────┬───────────┬─────────────┘\n",
    "           │           │\n",
    "  ┌────────▼───┐  ┌───▼────────┐\n",
    "  │ Position   │  │ Map        │\n",
    "  │ (x, y, θ)  │  │ (3D Cloud) │\n",
    "  └────────────┘  └────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 KISS-ICP SLAM\n",
    "\n",
    "Das G1-Repository nutzt **KISS-ICP** (Keep It Small and Simple - Iterative Closest Point):\n",
    "\n",
    "**Vorteile:**\n",
    "- ✓ Echtzeit-fähig (20+ Hz)\n",
    "- ✓ Keine Loop-Closure benötigt\n",
    "- ✓ Robust gegen Drift\n",
    "- ✓ Python-Implementation\n",
    "- ✓ Funktioniert mit beliebigem 3D LiDAR\n",
    "\n",
    "**Algorithmus:**\n",
    "1. Empfange neuen LiDAR-Scan\n",
    "2. Voxel-Downsampling (Reduktion Punktanzahl)\n",
    "3. ICP-Matching mit vorheriger Karte\n",
    "4. Schätze Transformation (Δx, Δy, Δθ)\n",
    "5. Update Roboter-Pose\n",
    "6. Füge Scan zur Karte hinzu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. LiDAR-Integration: Livox MID-360\n",
    "\n",
    "### 2.1 Livox MID-360 Spezifikationen\n",
    "\n",
    "| Spezifikation | Wert |\n",
    "|---------------|------|\n",
    "| **Sichtfeld (FoV)** | 360° horizontal, ±59° vertikal |\n",
    "| **Reichweite** | 0.05 - 70 m (bei 10% reflectivity) |\n",
    "| **Punktrate** | 200,000 pts/s |\n",
    "| **Genauigkeit** | < 2 cm (@ 20m) |\n",
    "| **Scan-Pattern** | Non-repetitive rosette |\n",
    "| **Interface** | Ethernet (UDP) |\n",
    "| **IP** | 192.168.1.1 (default) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 LiDAR Setup & Konfiguration\n",
    "\n",
    "**Netzwerk-Konfiguration:**\n",
    "\n",
    "1. Verbinden Sie den MID-360 via Ethernet\n",
    "2. Setzen Sie Ihren PC auf statische IP: `192.168.1.50`\n",
    "3. Konfigurieren Sie `mid360_config.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: mid360_config.json\n",
    "config_example = {\n",
    "    \"MID360\": {\n",
    "        \"lidar_net_info\": {\n",
    "            \"cmd_data_port\": 56100,\n",
    "            \"push_msg_port\": 56200,\n",
    "            \"point_data_port\": 56300,\n",
    "            \"imu_data_port\": 56400,\n",
    "            \"log_data_port\": 56500\n",
    "        },\n",
    "        \"host_net_info\": {\n",
    "            \"cmd_data_ip\": \"192.168.1.50\",  # Ihre PC-IP!\n",
    "            \"cmd_data_port\": 56101,\n",
    "            \"push_msg_ip\": \"192.168.1.50\",\n",
    "            \"push_msg_port\": 56201,\n",
    "            \"point_data_ip\": \"192.168.1.50\",\n",
    "            \"point_data_port\": 56301,\n",
    "            \"imu_data_ip\": \"192.168.1.50\",\n",
    "            \"imu_data_port\": 56401,\n",
    "            \"log_data_ip\": \"192.168.1.50\",\n",
    "            \"log_data_port\": 56501\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "print(\"Beispiel-Konfiguration für Livox MID-360:\")\n",
    "print(json.dumps(config_example, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Live Point-Cloud Viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup für LiDAR-Visualisierung\n",
    "import sys\n",
    "sys.path.append('../unitree_g1_vibes')\n",
    "\n",
    "# Importiere LiDAR-Wrapper\n",
    "# from livox2_python import LivoxLidar\n",
    "\n",
    "print(\"LiDAR-Treiber verfügbar!\")\n",
    "print(\"\\nStarten mit:\")\n",
    "print(\"cd ../unitree_g1_vibes\")\n",
    "print(\"python3 live_points.py\")\n",
    "print(\"\\nDies öffnet Open3D-Fenster mit Live-Point-Cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Was passiert in `live_points.py`:**\n",
    "\n",
    "```python\n",
    "# Vereinfachte Version:\n",
    "import open3d as o3d\n",
    "from livox2_python import LivoxLidar\n",
    "\n",
    "# Initialize LiDAR\n",
    "lidar = LivoxLidar(config_file=\"mid360_config.json\")\n",
    "lidar.start()\n",
    "\n",
    "# Open3D Visualizer\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(\"Livox MID-360 Live View\")\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "vis.add_geometry(pcd)\n",
    "\n",
    "while True:\n",
    "    # Empfange neuen Frame\n",
    "    points = lidar.get_latest_points()  # Nx3 array\n",
    "    \n",
    "    # Update Point-Cloud\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.paint_uniform_color([0.5, 0.5, 1.0])  # Blau\n",
    "    \n",
    "    # Render\n",
    "    vis.update_geometry(pcd)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. SLAM mit KISS-ICP\n",
    "\n",
    "### 3.1 SLAM Starten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLAM mit KISS-ICP starten\n",
    "# Im Terminal:\n",
    "# cd ../unitree_g1_vibes\n",
    "# python3 live_slam.py\n",
    "\n",
    "print(\"SLAM-Visualisierung:\")\n",
    "print(\"- Grüne Punkte: Neue Scans\")\n",
    "print(\"- Weiße Punkte: Karte (akkumuliert)\")\n",
    "print(\"- Rote Linie: Trajektorie (Roboter-Pfad)\")\n",
    "print(\"- Koordinatensystem: Aktuelle Pose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 SLAM-Daten extrahieren\n",
    "\n",
    "**Pose-Tracking:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: SLAM-Daten auslesen\n",
    "# (Pseudo-Code basierend auf live_slam.py)\n",
    "\n",
    "from kiss_icp.kiss_icp import KissICP\n",
    "import numpy as np\n",
    "\n",
    "# Initialize SLAM\n",
    "# slam = KissICP()\n",
    "\n",
    "# Process new scan\n",
    "# points = lidar.get_latest_points()  # Nx3 numpy array\n",
    "# pose = slam.register_frame(points)  # 4x4 transformation matrix\n",
    "\n",
    "# Extrahiere Position\n",
    "def extract_position_2d(pose_matrix):\n",
    "    \"\"\"\n",
    "    Extrahiert (x, y, theta) aus 4x4 Transformationsmatrix\n",
    "    \"\"\"\n",
    "    x = pose_matrix[0, 3]\n",
    "    y = pose_matrix[1, 3]\n",
    "    \n",
    "    # Rotation um Z-Achse\n",
    "    theta = np.arctan2(pose_matrix[1, 0], pose_matrix[0, 0])\n",
    "    \n",
    "    return x, y, theta\n",
    "\n",
    "# Beispiel:\n",
    "example_pose = np.eye(4)\n",
    "example_pose[0, 3] = 1.5  # x = 1.5 m\n",
    "example_pose[1, 3] = 0.8  # y = 0.8 m\n",
    "\n",
    "x, y, theta = extract_position_2d(example_pose)\n",
    "print(f\"Position: x={x:.2f}m, y={y:.2f}m, theta={np.degrees(theta):.1f}°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 2D Occupancy Grid erstellen\n",
    "\n",
    "Für Navigation benötigen wir eine **2D-Karte** (Occupancy Grid):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_occupancy_grid(point_cloud, resolution=0.1, size=20.0):\n",
    "    \"\"\"\n",
    "    Erzeugt 2D Occupancy Grid aus 3D Point-Cloud\n",
    "    \n",
    "    point_cloud: Nx3 numpy array (x, y, z)\n",
    "    resolution: Grid-Auflösung in Metern\n",
    "    size: Kartengröße (size x size Meter)\n",
    "    \n",
    "    Returns: 2D array (occupied=1, free=0, unknown=-1)\n",
    "    \"\"\"\n",
    "    grid_size = int(size / resolution)\n",
    "    grid = np.zeros((grid_size, grid_size), dtype=np.int8)\n",
    "    grid[:] = -1  # Initialisiere als unbekannt\n",
    "    \n",
    "    # Filter: Nur Punkte nahe Bodenhöhe (z < 2m)\n",
    "    ground_points = point_cloud[point_cloud[:, 2] < 2.0]\n",
    "    \n",
    "    # Konvertiere zu Grid-Koordinaten\n",
    "    center = grid_size // 2\n",
    "    for point in ground_points:\n",
    "        x, y, z = point\n",
    "        \n",
    "        # Grid-Indizes\n",
    "        i = int(center + x / resolution)\n",
    "        j = int(center + y / resolution)\n",
    "        \n",
    "        # Bounds-Check\n",
    "        if 0 <= i < grid_size and 0 <= j < grid_size:\n",
    "            grid[j, i] = 1  # Belegt\n",
    "    \n",
    "    return grid\n",
    "\n",
    "# Test mit synthetischen Daten:\n",
    "# Simuliere Raum mit Wänden\n",
    "test_points = []\n",
    "\n",
    "# Wand rechts (x=5m)\n",
    "for y in np.linspace(-5, 5, 100):\n",
    "    test_points.append([5.0, y, 0.5])\n",
    "\n",
    "# Wand links (x=-5m)\n",
    "for y in np.linspace(-5, 5, 100):\n",
    "    test_points.append([-5.0, y, 0.5])\n",
    "\n",
    "# Hindernis in der Mitte\n",
    "for x in np.linspace(-1, 1, 50):\n",
    "    for y in np.linspace(-1, 1, 50):\n",
    "        test_points.append([x, y, 0.8])\n",
    "\n",
    "test_cloud = np.array(test_points)\n",
    "\n",
    "# Erstelle Grid\n",
    "grid = create_occupancy_grid(test_cloud, resolution=0.1, size=12.0)\n",
    "\n",
    "# Visualisiere\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(grid, cmap='gray_r', origin='lower', extent=[-6, 6, -6, 6])\n",
    "plt.colorbar(label='Occupancy (1=belegt, 0=frei, -1=unbekannt)')\n",
    "plt.xlabel('X [m]')\n",
    "plt.ylabel('Y [m]')\n",
    "plt.title('2D Occupancy Grid aus LiDAR-Daten')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Grid-Größe: {grid.shape}\")\n",
    "print(f\"Belegte Zellen: {np.sum(grid == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Globale Pfadplanung\n",
    "\n",
    "### 4.1 A* Algorithmus\n",
    "\n",
    "**A*** ist der Standard für Grid-basierte Pfadplanung:\n",
    "\n",
    "**Algorithmus:**\n",
    "1. Start: Open-Liste = {Start-Knoten}, Closed-Liste = {}\n",
    "2. Wähle Knoten mit kleinstem f(n) = g(n) + h(n) aus Open-Liste\n",
    "   - g(n) = Kosten von Start zu n\n",
    "   - h(n) = Heuristik (geschätzte Kosten von n zu Ziel)\n",
    "3. Wenn Ziel erreicht → Rekonstruiere Pfad\n",
    "4. Expandiere Nachbarn, update Open-/Closed-Listen\n",
    "5. Wiederhole ab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "\n",
    "def astar_planning(grid, start, goal):\n",
    "    \"\"\"\n",
    "    A* Pfadplanung auf 2D Occupancy Grid\n",
    "    \n",
    "    grid: 2D numpy array (1=belegt, 0=frei)\n",
    "    start: (x, y) tuple\n",
    "    goal: (x, y) tuple\n",
    "    \n",
    "    Returns: Liste von (x, y) Wegpunkten\n",
    "    \"\"\"\n",
    "    def heuristic(a, b):\n",
    "        # Euklidische Distanz\n",
    "        return np.sqrt((a[0] - b[0])**2 + (a[1] - b[1])**2)\n",
    "    \n",
    "    def get_neighbors(pos):\n",
    "        # 8-Konnektivität\n",
    "        directions = [\n",
    "            (1, 0), (-1, 0), (0, 1), (0, -1),  # Cardinal\n",
    "            (1, 1), (1, -1), (-1, 1), (-1, -1)  # Diagonal\n",
    "        ]\n",
    "        neighbors = []\n",
    "        for dx, dy in directions:\n",
    "            nx, ny = pos[0] + dx, pos[1] + dy\n",
    "            # Check bounds und Hindernisse\n",
    "            if (0 <= nx < grid.shape[1] and \n",
    "                0 <= ny < grid.shape[0] and \n",
    "                grid[ny, nx] != 1):  # Nicht belegt\n",
    "                cost = 1.414 if dx != 0 and dy != 0 else 1.0  # Diagonal teurer\n",
    "                neighbors.append(((nx, ny), cost))\n",
    "        return neighbors\n",
    "    \n",
    "    # Initialisierung\n",
    "    open_set = []\n",
    "    heapq.heappush(open_set, (0, start))\n",
    "    came_from = {}\n",
    "    g_score = {start: 0}\n",
    "    f_score = {start: heuristic(start, goal)}\n",
    "    \n",
    "    while open_set:\n",
    "        current_f, current = heapq.heappop(open_set)\n",
    "        \n",
    "        # Ziel erreicht?\n",
    "        if current == goal:\n",
    "            # Rekonstruiere Pfad\n",
    "            path = [current]\n",
    "            while current in came_from:\n",
    "                current = came_from[current]\n",
    "                path.append(current)\n",
    "            path.reverse()\n",
    "            return path\n",
    "        \n",
    "        # Expandiere Nachbarn\n",
    "        for neighbor, cost in get_neighbors(current):\n",
    "            tentative_g = g_score[current] + cost\n",
    "            \n",
    "            if neighbor not in g_score or tentative_g < g_score[neighbor]:\n",
    "                came_from[neighbor] = current\n",
    "                g_score[neighbor] = tentative_g\n",
    "                f_score[neighbor] = tentative_g + heuristic(neighbor, goal)\n",
    "                heapq.heappush(open_set, (f_score[neighbor], neighbor))\n",
    "    \n",
    "    return None  # Kein Pfad gefunden\n",
    "\n",
    "# Test:\n",
    "start_pos = (10, 10)\n",
    "goal_pos = (110, 110)\n",
    "\n",
    "path = astar_planning(grid, start_pos, goal_pos)\n",
    "\n",
    "if path:\n",
    "    print(f\"✓ Pfad gefunden mit {len(path)} Wegpunkten\")\n",
    "    \n",
    "    # Visualisiere\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(grid, cmap='gray_r', origin='lower', extent=[-6, 6, -6, 6])\n",
    "    \n",
    "    # Konvertiere Pfad zu Welt-Koordinaten\n",
    "    resolution = 0.1\n",
    "    center = grid.shape[0] // 2\n",
    "    path_world = [(x - center) * resolution for x, y in path]\n",
    "    path_world_y = [(y - center) * resolution for x, y in path]\n",
    "    \n",
    "    plt.plot(path_world, path_world_y, 'r-', linewidth=2, label='A* Pfad')\n",
    "    plt.plot(path_world[0], path_world_y[0], 'go', markersize=10, label='Start')\n",
    "    plt.plot(path_world[-1], path_world_y[-1], 'ro', markersize=10, label='Ziel')\n",
    "    \n",
    "    plt.xlabel('X [m]')\n",
    "    plt.ylabel('Y [m]')\n",
    "    plt.title('A* Pfadplanung')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"✗ Kein Pfad gefunden!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 RRT (Rapidly-exploring Random Tree)\n",
    "\n",
    "**Alternative zu A*:** Besser für hochdimensionale Räume und komplexe Hindernisse.\n",
    "\n",
    "**Algorithmus:**\n",
    "1. Baum initialisieren mit Start-Knoten\n",
    "2. Wiederhole N mal:\n",
    "   - Sample zufälligen Punkt\n",
    "   - Finde nächsten Baum-Knoten\n",
    "   - Erweitere Baum in Richtung Sample\n",
    "   - Prüfe Kollision\n",
    "3. Wenn Ziel erreicht → Extrahiere Pfad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified RRT implementation\n",
    "def rrt_planning(grid, start, goal, max_iterations=1000, step_size=5):\n",
    "    \"\"\"\n",
    "    RRT Pfadplanung\n",
    "    \n",
    "    grid: 2D numpy array\n",
    "    start, goal: (x, y) tuples\n",
    "    max_iterations: Maximale Anzahl Iterationen\n",
    "    step_size: Schrittgröße beim Erweitern\n",
    "    \"\"\"\n",
    "    class Node:\n",
    "        def __init__(self, pos, parent=None):\n",
    "            self.pos = pos\n",
    "            self.parent = parent\n",
    "    \n",
    "    def distance(p1, p2):\n",
    "        return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "    \n",
    "    def is_collision_free(p1, p2):\n",
    "        # Line-of-sight check\n",
    "        n_steps = int(distance(p1, p2) / 1.0)\n",
    "        for i in range(n_steps + 1):\n",
    "            alpha = i / max(n_steps, 1)\n",
    "            x = int(p1[0] + alpha * (p2[0] - p1[0]))\n",
    "            y = int(p1[1] + alpha * (p2[1] - p1[1]))\n",
    "            if not (0 <= x < grid.shape[1] and 0 <= y < grid.shape[0]):\n",
    "                return False\n",
    "            if grid[y, x] == 1:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    # Initialize\n",
    "    tree = [Node(start)]\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Sample random point (90%) oder Ziel (10%)\n",
    "        if np.random.rand() < 0.1:\n",
    "            sample = goal\n",
    "        else:\n",
    "            sample = (\n",
    "                np.random.randint(0, grid.shape[1]),\n",
    "                np.random.randint(0, grid.shape[0])\n",
    "            )\n",
    "        \n",
    "        # Find nearest node\n",
    "        nearest_node = min(tree, key=lambda n: distance(n.pos, sample))\n",
    "        \n",
    "        # Steer towards sample\n",
    "        direction = np.array(sample) - np.array(nearest_node.pos)\n",
    "        length = np.linalg.norm(direction)\n",
    "        if length > step_size:\n",
    "            direction = direction / length * step_size\n",
    "        \n",
    "        new_pos = tuple((np.array(nearest_node.pos) + direction).astype(int))\n",
    "        \n",
    "        # Check collision\n",
    "        if is_collision_free(nearest_node.pos, new_pos):\n",
    "            new_node = Node(new_pos, nearest_node)\n",
    "            tree.append(new_node)\n",
    "            \n",
    "            # Check if goal reached\n",
    "            if distance(new_pos, goal) < step_size:\n",
    "                # Reconstruct path\n",
    "                path = []\n",
    "                current = new_node\n",
    "                while current:\n",
    "                    path.append(current.pos)\n",
    "                    current = current.parent\n",
    "                path.reverse()\n",
    "                return path\n",
    "    \n",
    "    return None  # No path found\n",
    "\n",
    "print(\"RRT-Funktion definiert.\")\n",
    "print(\"Test mit: rrt_planning(grid, start_pos, goal_pos)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Lokale Hindernisvermeidung\n",
    "\n",
    "### 5.1 Dynamic Window Approach (DWA)\n",
    "\n",
    "**Problem:** Globaler Pfad berücksichtigt keine dynamischen Hindernisse.\n",
    "\n",
    "**Lösung: DWA** - Lokale Trajektorien-Optimierung\n",
    "\n",
    "**Algorithmus:**\n",
    "1. Berechne \"Dynamic Window\" - erlaubte (vx, vy, ω) basierend auf:\n",
    "   - Maximaler Beschleunigung\n",
    "   - Aktueller Geschwindigkeit\n",
    "2. Sample Trajektorien in diesem Window\n",
    "3. Bewerte jede Trajektorie nach:\n",
    "   - Distanz zu Hindernissen\n",
    "   - Fortschritt zum Ziel\n",
    "   - Geschwindigkeit (höher = besser)\n",
    "4. Wähle beste Trajektorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified DWA\n",
    "def dynamic_window_approach(current_vel, goal_pos, obstacles, dt=0.1):\n",
    "    \"\"\"\n",
    "    DWA für lokale Hindernisvermeidung\n",
    "    \n",
    "    current_vel: (vx, vy, omega) aktuell\n",
    "    goal_pos: (x, y) Zielposition\n",
    "    obstacles: Liste von (x, y) Hindernispositionen\n",
    "    dt: Zeitschritt\n",
    "    \n",
    "    Returns: (vx, vy, omega) beste Geschwindigkeit\n",
    "    \"\"\"\n",
    "    # Grenzen\n",
    "    max_v = 0.6  # m/s\n",
    "    max_omega = 0.6  # rad/s\n",
    "    max_accel = 1.0  # m/s²\n",
    "    max_alpha = 1.0  # rad/s²\n",
    "    \n",
    "    # Dynamic Window\n",
    "    vx_min = max(-max_v, current_vel[0] - max_accel * dt)\n",
    "    vx_max = min(max_v, current_vel[0] + max_accel * dt)\n",
    "    omega_min = max(-max_omega, current_vel[2] - max_alpha * dt)\n",
    "    omega_max = min(max_omega, current_vel[2] + max_alpha * dt)\n",
    "    \n",
    "    # Sample Trajektorien\n",
    "    best_score = -np.inf\n",
    "    best_vel = current_vel\n",
    "    \n",
    "    for vx in np.linspace(vx_min, vx_max, 10):\n",
    "        for omega in np.linspace(omega_min, omega_max, 10):\n",
    "            # Simuliere Trajektorie (1 Sekunde)\n",
    "            sim_time = 1.0\n",
    "            sim_x, sim_y, sim_theta = 0, 0, 0\n",
    "            \n",
    "            for t in np.arange(0, sim_time, dt):\n",
    "                sim_x += vx * np.cos(sim_theta) * dt\n",
    "                sim_y += vx * np.sin(sim_theta) * dt\n",
    "                sim_theta += omega * dt\n",
    "            \n",
    "            # Evaluate\n",
    "            # 1. Distanz zum Ziel\n",
    "            goal_dist = np.sqrt((goal_pos[0] - sim_x)**2 + (goal_pos[1] - sim_y)**2)\n",
    "            goal_score = 1.0 / (1.0 + goal_dist)\n",
    "            \n",
    "            # 2. Hindernisdistanz (Mindestabstand)\n",
    "            min_obstacle_dist = np.inf\n",
    "            for obs_x, obs_y in obstacles:\n",
    "                dist = np.sqrt((obs_x - sim_x)**2 + (obs_y - sim_y)**2)\n",
    "                min_obstacle_dist = min(min_obstacle_dist, dist)\n",
    "            \n",
    "            if min_obstacle_dist < 0.3:  # Zu nah!\n",
    "                obstacle_score = -10.0\n",
    "            else:\n",
    "                obstacle_score = min_obstacle_dist\n",
    "            \n",
    "            # 3. Geschwindigkeits-Bonus\n",
    "            velocity_score = abs(vx) / max_v\n",
    "            \n",
    "            # Gesamt-Score\n",
    "            total_score = (\n",
    "                2.0 * goal_score +\n",
    "                1.0 * obstacle_score +\n",
    "                0.5 * velocity_score\n",
    "            )\n",
    "            \n",
    "            if total_score > best_score:\n",
    "                best_score = total_score\n",
    "                best_vel = (vx, 0.0, omega)\n",
    "    \n",
    "    return best_vel\n",
    "\n",
    "# Test:\n",
    "current_vel = (0.2, 0.0, 0.0)\n",
    "goal_pos = (5.0, 0.0)\n",
    "obstacles = [(2.0, 0.5), (3.0, -0.5)]\n",
    "\n",
    "best_vel = dynamic_window_approach(current_vel, goal_pos, obstacles)\n",
    "print(f\"Beste Geschwindigkeit: vx={best_vel[0]:.2f} m/s, omega={best_vel[2]:.2f} rad/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. RealSense Integration (RGB-D)\n",
    "\n",
    "### 6.1 RealSense D435i Übersicht\n",
    "\n",
    "Zusätzlich zum LiDAR hat der G1 eine **Intel RealSense D435i** Kamera:\n",
    "\n",
    "| Spezifikation | Wert |\n",
    "|---------------|------|\n",
    "| **RGB** | 1920×1080 @ 30 FPS |\n",
    "| **Tiefe** | 1280×720 @ 30 FPS |\n",
    "| **Reichweite** | 0.3 - 10 m |\n",
    "| **FoV** | 69° H × 42° V (Tiefe) |\n",
    "| **IMU** | Accel + Gyro @ 200 Hz |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 RealSense Streaming Setup\n",
    "\n",
    "Das Repository nutzt **GStreamer** für low-latency Streaming:\n",
    "\n",
    "**Auf Jetson (G1):**\n",
    "```bash\n",
    "python3 jetson_realsense_stream.py --client-ip <PC_IP>\n",
    "```\n",
    "\n",
    "**Auf PC:**\n",
    "```bash\n",
    "python3 receive_realsense_gst.py\n",
    "```\n",
    "\n",
    "**Ports:**\n",
    "- 5600: RGB (H.264 encoded)\n",
    "- 5602: Depth Colormap (H.264 encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Workshop: Navigationsaufgabe mit Hindernisfeld\n",
    "\n",
    "### Aufgabe: Navigiere durch Labyrinth\n",
    "\n",
    "**Szenario:**\n",
    "- Roboter startet bei (0, 0)\n",
    "- Ziel: (8, 8)\n",
    "- Hindernisse verteilt in Umgebung\n",
    "\n",
    "**Schritte:**\n",
    "1. Erstelle SLAM-Karte mit LiDAR\n",
    "2. Plane globalen Pfad mit A*\n",
    "3. Folge Pfad mit lokalem Controller (DWA)\n",
    "4. Erreiche Ziel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vollständiges Navigations-Beispiel (Pseudo-Code)\n",
    "\n",
    "def navigate_to_goal(bot, slam, goal_pos):\n",
    "    \"\"\"\n",
    "    Vollständige Navigation zu Zielpunkt\n",
    "    \n",
    "    bot: LocoClient Instanz\n",
    "    slam: KISS-ICP SLAM Instanz\n",
    "    goal_pos: (x, y) Zielposition\n",
    "    \"\"\"\n",
    "    print(f\"Navigiere zu Ziel: {goal_pos}\")\n",
    "    \n",
    "    # 1. Erstelle Karte\n",
    "    print(\"Scanne Umgebung...\")\n",
    "    # point_cloud = slam.get_map()\n",
    "    # grid = create_occupancy_grid(point_cloud)\n",
    "    \n",
    "    # 2. Plane globalen Pfad\n",
    "    # current_pose = slam.get_pose()\n",
    "    # start_grid = world_to_grid(current_pose[:2])\n",
    "    # goal_grid = world_to_grid(goal_pos)\n",
    "    # path = astar_planning(grid, start_grid, goal_grid)\n",
    "    \n",
    "    # if not path:\n",
    "    #     print(\"Kein Pfad gefunden!\")\n",
    "    #     return False\n",
    "    \n",
    "    print(f\"Pfad geplant mit {len(path) if 'path' in locals() else 'N'} Wegpunkten\")\n",
    "    \n",
    "    # 3. Folge Pfad\n",
    "    # for waypoint in path:\n",
    "    #     while True:\n",
    "    #         # Aktuelle Position\n",
    "    #         current_pose = slam.get_pose()\n",
    "    #         current_x, current_y, current_theta = extract_position_2d(current_pose)\n",
    "    #         \n",
    "    #         # Distanz zum Wegpunkt\n",
    "    #         waypoint_world = grid_to_world(waypoint)\n",
    "    #         dist = np.sqrt((waypoint_world[0] - current_x)**2 + \n",
    "    #                       (waypoint_world[1] - current_y)**2)\n",
    "    #         \n",
    "    #         if dist < 0.2:  # Wegpunkt erreicht\n",
    "    #             break\n",
    "    #         \n",
    "    #         # DWA für lokale Steuerung\n",
    "    #         obstacles = detect_obstacles_from_lidar()\n",
    "    #         current_vel = (0.0, 0.0, 0.0)  # TODO: Von Roboter auslesen\n",
    "    #         best_vel = dynamic_window_approach(current_vel, waypoint_world, obstacles)\n",
    "    #         \n",
    "    #         # Sende an Roboter\n",
    "    #         bot.Move(best_vel[0], best_vel[1], best_vel[2])\n",
    "    #         time.sleep(0.1)\n",
    "    \n",
    "    # Finale Stopp\n",
    "    # bot.StopMove()\n",
    "    print(\"Ziel erreicht!\")\n",
    "    return True\n",
    "\n",
    "print(\"Navigations-Funktion definiert.\")\n",
    "print(\"Verwendung: navigate_to_goal(bot, slam, (8.0, 8.0))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Zusammenfassung Tag 3\n",
    "\n",
    "### Gelernte Konzepte:\n",
    "✓ SLAM mit KISS-ICP  \n",
    "✓ LiDAR-Integration (Livox MID-360)  \n",
    "✓ Occupancy Grid Mapping  \n",
    "✓ Globale Pfadplanung (A*, RRT)  \n",
    "✓ Lokale Hindernisvermeidung (DWA)  \n",
    "✓ RealSense RGB-D Integration  \n",
    "\n",
    "### Wichtige Dateien:\n",
    "- `live_slam.py` - SLAM mit Visualisierung\n",
    "- `livox2_python.py` - LiDAR SDK Wrapper\n",
    "- `jetson_realsense_stream.py` - RealSense Sender\n",
    "- `receive_realsense_gst.py` - RealSense Receiver\n",
    "- `mid360_config.json` - LiDAR Konfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Hausaufgabe / Vertiefung\n",
    "\n",
    "**Aufgabe 1:** SLAM-Mapping\n",
    "- Starten Sie `live_slam.py`\n",
    "- Fahren Sie den Roboter durch einen Raum\n",
    "- Exportieren Sie die finale Karte\n",
    "\n",
    "**Aufgabe 2:** A* vs. RRT Vergleich\n",
    "- Implementieren Sie beide Algorithmen\n",
    "- Vergleichen Sie Laufzeit und Pfad-Qualität\n",
    "- Testen Sie mit verschiedenen Karten\n",
    "\n",
    "**Aufgabe 3:** DWA Tuning\n",
    "- Variieren Sie DWA-Parameter (Gewichte)\n",
    "- Beobachten Sie Einfluss auf Verhalten\n",
    "- Dokumentieren Sie optimale Parameter\n",
    "\n",
    "**Bonusaufgabe:** Implementieren Sie **Hybrid A*** für glattere Pfade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Nächster Tag: Wahrnehmung, Anwendung & Transfer\n",
    "\n",
    "**Vorschau Tag 4:**\n",
    "- Visuelle Wahrnehmung mit Deep Learning\n",
    "- Objekt- und Umgebungserkennung\n",
    "- Integration: SLAM + Perception + Control\n",
    "- Projektarbeit: Real-World Challenge\n",
    "- Transfer in eigene Projekte"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
