{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag 2: Bewegungssteuerung & Laufverhalten\n",
    "## Unitree G1 Humanoid Roboter Academy\n",
    "\n",
    "### Agenda Tag 2:\n",
    "1. Dynamisches Gehen & Stabilität\n",
    "2. Regelungstechnik für Humanoide\n",
    "3. Reinforcement Learning Ansätze\n",
    "4. Keyboard-Tele-Operation (Workshop)\n",
    "5. Trajektorien-Planung\n",
    "6. Praktische Aufgaben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Dynamisches Gehen bei Humanoiden\n",
    "\n",
    "### 1.1 Herausforderungen beim bipedalen Gehen\n",
    "\n",
    "Im Gegensatz zu Radrobotern oder Quadrupeds müssen Humanoide:\n",
    "\n",
    "**1. Dynamische Balance halten:**\n",
    "```\n",
    "       ┌─────┐\n",
    "       │ CoM │  ← Center of Mass (Schwerpunkt)\n",
    "       └──┬──┘\n",
    "          │\n",
    "    ┌─────┴─────┐\n",
    "    │           │\n",
    "   ┌┴┐         ┌┴┐\n",
    "   │L│         │R│  ← Support Polygon\n",
    "   └─┘         └─┘\n",
    "```\n",
    "\n",
    "**Bedingung für Stabilität:**\n",
    "- Center of Mass (CoM) muss über dem Support Polygon bleiben\n",
    "- Bei Einbeinstand: sehr kleines Polygon!\n",
    "- Bei Zweibeinstand: größeres Polygon\n",
    "\n",
    "**2. Schwungphasen koordinieren:**\n",
    "- Swing Phase: Bein in der Luft\n",
    "- Stance Phase: Bein trägt Gewicht\n",
    "- Doppelstützphase: Beide Füße am Boden\n",
    "\n",
    "**3. Dynamische Kräfte kompensieren:**\n",
    "- Bodenreaktionskräfte\n",
    "- Trägheitskräfte während Beschleunigung\n",
    "- Störungen (Unebenheiten, Schubser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Zero Moment Point (ZMP) Stabilität\n",
    "\n",
    "**ZMP-Konzept:**\n",
    "- Punkt am Boden, an dem die Summe aller Momente = 0\n",
    "- Wenn ZMP innerhalb des Support Polygon → stabil\n",
    "- Wenn ZMP außerhalb → Roboter kippt\n",
    "\n",
    "**Mathematische Bedingung:**\n",
    "```\n",
    "Σ τ_ZMP = 0\n",
    "→ Roboter passt CoM-Trajektorie an, um ZMP im Polygon zu halten\n",
    "```\n",
    "\n",
    "**Beispiel: Vorwärtsgehen**\n",
    "```\n",
    "1. CoM verschiebt sich über rechten Fuß\n",
    "2. Linker Fuß hebt ab (Swing)\n",
    "3. Linker Fuß setzt vor rechtem auf\n",
    "4. CoM verschiebt sich über linken Fuß\n",
    "5. Rechter Fuß hebt ab...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Regelungstechnik im G1\n",
    "\n",
    "### 2.1 Hierarchische Regelungsarchitektur\n",
    "\n",
    "```\n",
    "┌──────────────────────────────────────────┐\n",
    "│ High-Level: Bewegungsplanung            │\n",
    "│ Input: Zielgeschwindigkeit (vx, vy, ω)  │\n",
    "│ Output: Fußplatzierungs-Trajektorien    │\n",
    "└────────────────┬─────────────────────────┘\n",
    "                 │\n",
    "┌────────────────▼─────────────────────────┐\n",
    "│ Mid-Level: Whole-Body Controller        │\n",
    "│ - Inverse Kinematik                      │\n",
    "│ - CoM-Trajektorien                       │\n",
    "│ - ZMP-Stabilisierung                     │\n",
    "│ Output: Gelenkwinkel-Sollwerte          │\n",
    "└────────────────┬─────────────────────────┘\n",
    "                 │\n",
    "┌────────────────▼─────────────────────────┐\n",
    "│ Low-Level: Motor Controller              │\n",
    "│ - PID-Regelung pro Gelenk               │\n",
    "│ - Drehmomenten-Kontrolle                │\n",
    "│ Output: Motor-Kommandos                  │\n",
    "└──────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 PID-Regelung auf Gelenkebene\n",
    "\n",
    "Jedes Gelenk hat einen **PID-Controller:**\n",
    "\n",
    "```python\n",
    "# Vereinfachtes Modell:\n",
    "def pid_control(q_target, q_current, dq_current, Kp, Kd, Ki):\n",
    "    \"\"\"\n",
    "    q_target: Ziel-Gelenkwinkel\n",
    "    q_current: Aktueller Gelenkwinkel\n",
    "    dq_current: Aktuelle Gelenkgeschwindigkeit\n",
    "    \"\"\"\n",
    "    error = q_target - q_current\n",
    "    \n",
    "    # Proportional term\n",
    "    P = Kp * error\n",
    "    \n",
    "    # Derivative term (Dämpfung)\n",
    "    D = Kd * (-dq_current)\n",
    "    \n",
    "    # Integral term (steady-state error)\n",
    "    I = Ki * integral_error\n",
    "    \n",
    "    tau = P + D + I  # Gesamt-Drehmoment\n",
    "    return tau\n",
    "```\n",
    "\n",
    "**Typische G1-Parameter:**\n",
    "- Beine: Kp=200, Kd=5 (steif für Gewichtsträger)\n",
    "- Arme: Kp=100, Kd=3 (weicher für Manipulation)\n",
    "- Hände: Kp=20, Kd=1 (sehr weich für Kontakt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Reinforcement Learning für Laufverhalten\n",
    "\n",
    "### 3.1 RL-Ansatz für Humanoide\n",
    "\n",
    "**Problem:** Klassische Regelung (ZMP, Inverse Kinematik) erfordert:\n",
    "- Genaue Modelle\n",
    "- Hand-tuning vieler Parameter\n",
    "- Schwierig für komplexes Terrain\n",
    "\n",
    "**Lösung: End-to-End RL**\n",
    "- Lerne Policy direkt aus Sensordaten → Motor-Kommandos\n",
    "- Training in Simulation (MuJoCo)\n",
    "- Transfer zu realem Roboter (Sim-to-Real)\n",
    "\n",
    "### 3.2 G1 Arm Reach RL-Environment\n",
    "\n",
    "Das Repository enthält ein **vollständiges RL-Setup** für Arm-Steuerung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup für RL-Experimente\n",
    "import sys\n",
    "sys.path.append('../unitree_g1_vibes/RL-shenanigans')\n",
    "\n",
    "# Importiere das Gymnasium Environment\n",
    "# from g1_arm_rl_env import G1ArmReachEnv\n",
    "\n",
    "print(\"RL Environment für G1 Arm-Steuerung verfügbar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 RL Environment Struktur\n",
    "\n",
    "**Observation Space (24-dim):**\n",
    "```python\n",
    "obs = [\n",
    "    q[0:7],           # Aktuelle Gelenkwinkel (7 DOF)\n",
    "    dq[0:7],          # Gelenkgeschwindigkeiten (7 DOF)\n",
    "    p_hand[0:3],      # Hand-Position (x, y, z)\n",
    "    p_goal[0:3],      # Ziel-Position (x, y, z)\n",
    "    delta_p[0:3],     # Vektor Hand→Ziel\n",
    "    step_fraction     # Fortschritt im Episode (0-1)\n",
    "]\n",
    "```\n",
    "\n",
    "**Action Space (7-dim):**\n",
    "```python\n",
    "action = Δq[0:7]  # Inkrementelle Gelenkwinkel-Änderungen\n",
    "                  # Jede Aktion: -0.05 bis +0.05 rad\n",
    "```\n",
    "\n",
    "**Reward Function:**\n",
    "```python\n",
    "reward = -5.0 * ||p_hand - p_goal||      # Distanz zum Ziel\n",
    "         - 0.1 * ||Δq||                   # Aktion-Penalty (smooth motion)\n",
    "         + 1.0 if goal_reached            # Bonus bei Erfolg\n",
    "         - 1.0 if self_collision          # Penalty bei Kollision\n",
    "         - 0.5 if joint_limit_exceeded    # Penalty bei Gelenkgrenzen\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Training Algorithms\n",
    "\n",
    "Das Setup unterstützt **3 Algorithmen** (Stable-Baselines3):\n",
    "\n",
    "| Algorithmus | Typ | Vorteile | Nachteile |\n",
    "|-------------|-----|----------|----------|\n",
    "| **PPO** | On-Policy | Stabil, einfach zu tunen | Sample-ineffizient |\n",
    "| **SAC** | Off-Policy | Sample-effizient, robust | Komplexer, mehr Hyperparameter |\n",
    "| **TD3** | Off-Policy | Deterministisch, schnell | Weniger stabil als SAC |\n",
    "\n",
    "**Typisches Training:**\n",
    "```bash\n",
    "cd ../unitree_g1_vibes/RL-shenanigans\n",
    "python3 train_g1_arm_policy.py \\\n",
    "    --algo ppo \\\n",
    "    --total-steps 2_000_000 \\\n",
    "    --num-envs 16 \\\n",
    "    --right-arm\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "- Checkpoints: `models/ppo_g1_right_XXXXXX.zip`\n",
    "- TensorBoard logs: `runs/g1_arm_reach/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Workshop: Keyboard Tele-Operation\n",
    "\n",
    "### 4.1 Keyboard Controller Übersicht\n",
    "\n",
    "Der `keyboard_controller.py` ist ein **vollständiges Teleop-System**:\n",
    "\n",
    "**Features:**\n",
    "- WASD-Steuerung (Vorwärts/Rückwärts/Links/Rechts)\n",
    "- QE-Rotation (Yaw links/rechts)\n",
    "- Space: Sofort-Stopp\n",
    "- Shift: Turbo-Modus (höhere Geschwindigkeit)\n",
    "- Esc: Not-Aus (Damp-Modus)\n",
    "- Kontinuierliches Velocity-Update (10 Hz)\n",
    "\n",
    "### 4.2 Starten des Controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In einem separaten Terminal ausführen:\n",
    "# cd ../unitree_g1_vibes\n",
    "# python3 keyboard_controller.py --iface enp68s0f1\n",
    "\n",
    "print(\"Keyboard Controller Anleitung:\")\n",
    "print(\"================================\")\n",
    "print(\"W/S    : Vorwärts/Rückwärts\")\n",
    "print(\"A/D    : Rotation Links/Rechts\")\n",
    "print(\"Q/E    : Seitwärts Links/Rechts\")\n",
    "print(\"Space  : Sofort Stoppen\")\n",
    "print(\"Shift  : Turbo-Modus (halten)\")\n",
    "print(\"Z      : Damp & Beenden\")\n",
    "print(\"Esc    : Not-Aus\")\n",
    "print(\"================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Internes Funktionsprinzip\n",
    "\n",
    "```python\n",
    "# Vereinfachte Version des Controllers:\n",
    "from pynput import keyboard\n",
    "import threading\n",
    "\n",
    "class KeyboardController:\n",
    "    def __init__(self, bot):\n",
    "        self.bot = bot\n",
    "        self.vx = 0.0\n",
    "        self.vy = 0.0\n",
    "        self.omega = 0.0\n",
    "        self.active_keys = set()\n",
    "        \n",
    "    def on_press(self, key):\n",
    "        if key == keyboard.Key.w:\n",
    "            self.active_keys.add('w')\n",
    "        elif key == keyboard.Key.s:\n",
    "            self.active_keys.add('s')\n",
    "        # ... weitere Keys\n",
    "        \n",
    "    def on_release(self, key):\n",
    "        if 'w' in str(key):\n",
    "            self.active_keys.discard('w')\n",
    "        # ... weitere Keys\n",
    "    \n",
    "    def update_loop(self):\n",
    "        \"\"\"Läuft mit 10 Hz\"\"\"\n",
    "        while self.running:\n",
    "            # Berechne Geschwindigkeiten aus active_keys\n",
    "            self.compute_velocities()\n",
    "            \n",
    "            # Sende an Roboter\n",
    "            self.bot.Move(self.vx, self.vy, self.omega, \n",
    "                         continuous_move=True)\n",
    "            \n",
    "            time.sleep(0.1)  # 10 Hz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Geschwindigkeits-Ramping\n",
    "\n",
    "**Problem:** Abrupte Geschwindigkeitsänderungen → instabil\n",
    "\n",
    "**Lösung:** Smooth Acceleration/Deceleration\n",
    "\n",
    "```python\n",
    "def smooth_velocity_update(current_vel, target_vel, accel_limit, dt):\n",
    "    \"\"\"\n",
    "    Begrenzt Beschleunigung auf accel_limit m/s²\n",
    "    \"\"\"\n",
    "    delta_v = target_vel - current_vel\n",
    "    max_delta = accel_limit * dt  # z.B. 1.0 m/s² * 0.1s = 0.1 m/s\n",
    "    \n",
    "    if abs(delta_v) > max_delta:\n",
    "        delta_v = max_delta * np.sign(delta_v)\n",
    "    \n",
    "    return current_vel + delta_v\n",
    "\n",
    "# Beispiel:\n",
    "# current_vx = 0.0\n",
    "# target_vx = 0.6  (W gedrückt)\n",
    "# \n",
    "# Nach 0.1s: vx = 0.1\n",
    "# Nach 0.2s: vx = 0.2\n",
    "# ...\n",
    "# Nach 0.6s: vx = 0.6 (erreicht)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Trajektorien-Planung\n",
    "\n",
    "### 5.1 Warum Trajektorien?\n",
    "\n",
    "**Problem mit direkter Geschwindigkeitssteuerung:**\n",
    "- Keine Garantie für smooth motion\n",
    "- Keine Kollisionsvermeidung\n",
    "- Keine Optimierung (z.B. minimale Energie)\n",
    "\n",
    "**Trajektorien-Planung:**\n",
    "- Plant gesamten Pfad von Start zu Ziel\n",
    "- Berücksichtigt Kinematik & Dynamik\n",
    "- Optimiert nach Kriterien (Zeit, Energie, Glattheit)\n",
    "\n",
    "### 5.2 Einfache Trajektorien: Geradlinige Bewegung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def linear_trajectory(start, goal, duration, dt=0.1):\n",
    "    \"\"\"\n",
    "    Erzeugt geradlinige Trajektorie von start zu goal\n",
    "    \n",
    "    start, goal: [x, y] Positionen\n",
    "    duration: Zeit in Sekunden\n",
    "    dt: Zeitschritt\n",
    "    \"\"\"\n",
    "    num_steps = int(duration / dt)\n",
    "    trajectory = []\n",
    "    \n",
    "    for i in range(num_steps + 1):\n",
    "        alpha = i / num_steps  # 0 bis 1\n",
    "        pos = start + alpha * (goal - start)\n",
    "        trajectory.append(pos)\n",
    "    \n",
    "    return np.array(trajectory)\n",
    "\n",
    "# Beispiel:\n",
    "start = np.array([0.0, 0.0])\n",
    "goal = np.array([2.0, 1.0])\n",
    "traj = linear_trajectory(start, goal, duration=5.0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(traj[:, 0], traj[:, 1], 'b-o', label='Trajektorie')\n",
    "plt.plot(start[0], start[1], 'go', markersize=10, label='Start')\n",
    "plt.plot(goal[0], goal[1], 'ro', markersize=10, label='Ziel')\n",
    "plt.xlabel('X [m]')\n",
    "plt.ylabel('Y [m]')\n",
    "plt.title('Geradlinige Trajektorie')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Trajektorie hat {len(traj)} Wegpunkte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Geschwindigkeitsprofile\n",
    "\n",
    "**Trapezoidal Velocity Profile:**\n",
    "- Beschleunigungsphase (konstant a)\n",
    "- Konstante Geschwindigkeit\n",
    "- Abbremsphase (konstant -a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapezoidal_velocity_profile(distance, v_max, a_max, dt=0.1):\n",
    "    \"\"\"\n",
    "    Erzeugt trapezförmiges Geschwindigkeitsprofil\n",
    "    \n",
    "    distance: Gesamtstrecke [m]\n",
    "    v_max: Maximale Geschwindigkeit [m/s]\n",
    "    a_max: Maximale Beschleunigung [m/s²]\n",
    "    \"\"\"\n",
    "    # Zeit für Beschleunigung\n",
    "    t_accel = v_max / a_max\n",
    "    \n",
    "    # Strecke während Beschleunigung\n",
    "    s_accel = 0.5 * a_max * t_accel**2\n",
    "    \n",
    "    # Strecke bei konstanter Geschwindigkeit\n",
    "    s_const = distance - 2 * s_accel\n",
    "    \n",
    "    if s_const < 0:\n",
    "        # Zu kurze Strecke, erreicht v_max nicht\n",
    "        v_max = np.sqrt(a_max * distance)\n",
    "        t_accel = v_max / a_max\n",
    "        s_accel = distance / 2\n",
    "        s_const = 0\n",
    "    \n",
    "    t_const = s_const / v_max if s_const > 0 else 0\n",
    "    \n",
    "    # Generiere Profil\n",
    "    time = []\n",
    "    velocity = []\n",
    "    position = []\n",
    "    \n",
    "    t = 0\n",
    "    s = 0\n",
    "    v = 0\n",
    "    \n",
    "    # Phase 1: Beschleunigung\n",
    "    while t < t_accel:\n",
    "        time.append(t)\n",
    "        v = a_max * t\n",
    "        velocity.append(v)\n",
    "        s = 0.5 * a_max * t**2\n",
    "        position.append(s)\n",
    "        t += dt\n",
    "    \n",
    "    # Phase 2: Konstante Geschwindigkeit\n",
    "    t_const_end = t + t_const\n",
    "    s_const_start = s\n",
    "    while t < t_const_end:\n",
    "        time.append(t)\n",
    "        velocity.append(v_max)\n",
    "        s = s_const_start + v_max * (t - t_accel)\n",
    "        position.append(s)\n",
    "        t += dt\n",
    "    \n",
    "    # Phase 3: Abbremsen\n",
    "    t_decel_start = t\n",
    "    s_decel_start = s\n",
    "    while s < distance:\n",
    "        time.append(t)\n",
    "        v = v_max - a_max * (t - t_decel_start)\n",
    "        if v < 0:\n",
    "            v = 0\n",
    "        velocity.append(v)\n",
    "        s = s_decel_start + v_max * (t - t_decel_start) - 0.5 * a_max * (t - t_decel_start)**2\n",
    "        position.append(s)\n",
    "        t += dt\n",
    "    \n",
    "    return np.array(time), np.array(velocity), np.array(position)\n",
    "\n",
    "# Beispiel:\n",
    "t, v, s = trapezoidal_velocity_profile(distance=5.0, v_max=0.6, a_max=0.5)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "ax1.plot(t, v, 'b-', linewidth=2)\n",
    "ax1.set_xlabel('Zeit [s]')\n",
    "ax1.set_ylabel('Geschwindigkeit [m/s]')\n",
    "ax1.set_title('Trapezförmiges Geschwindigkeitsprofil')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(t, s, 'r-', linewidth=2)\n",
    "ax2.set_xlabel('Zeit [s]')\n",
    "ax2.set_ylabel('Position [m]')\n",
    "ax2.set_title('Resultierende Position')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Gesamtzeit: {t[-1]:.2f} s\")\n",
    "print(f\"Endposition: {s[-1]:.2f} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Praktische Aufgaben\n",
    "\n",
    "### Aufgabe 1: Quadrat fahren\n",
    "\n",
    "**Ziel:** Programmieren Sie eine Sequenz, die den Roboter ein 2m×2m Quadrat abfahren lässt.\n",
    "\n",
    "**Hinweise:**\n",
    "- Nutzen Sie `bot.Move(vx, vy, omega)`\n",
    "- Planen Sie: Vorwärts → Rotation 90° → Vorwärts → ...\n",
    "- Berechnen Sie benötigte Zeit für jede Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung Aufgabe 1:\n",
    "import time\n",
    "\n",
    "def drive_square(bot, side_length=2.0, velocity=0.2):\n",
    "    \"\"\"\n",
    "    Fährt ein Quadrat mit gegebener Seitenlänge\n",
    "    \n",
    "    bot: LocoClient Instanz\n",
    "    side_length: Seitenlänge in Metern\n",
    "    velocity: Fahrgeschwindigkeit in m/s\n",
    "    \"\"\"\n",
    "    # Berechne Zeit für eine Seite\n",
    "    t_forward = side_length / velocity\n",
    "    \n",
    "    # Berechne Zeit für 90° Rotation\n",
    "    # 90° = π/2 rad, bei omega=0.3 rad/s\n",
    "    omega = 0.3\n",
    "    t_rotate = (np.pi / 2) / omega\n",
    "    \n",
    "    print(f\"Quadrat fahren: {side_length}m Seitenlänge\")\n",
    "    print(f\"Zeit pro Seite: {t_forward:.1f}s\")\n",
    "    print(f\"Zeit pro Drehung: {t_rotate:.1f}s\\n\")\n",
    "    \n",
    "    for i in range(4):\n",
    "        print(f\"Seite {i+1}/4: Vorwärts fahren...\")\n",
    "        # Vorwärts\n",
    "        # bot.Move(vx=velocity, vy=0, omega=0)\n",
    "        # time.sleep(t_forward)\n",
    "        \n",
    "        print(f\"Seite {i+1}/4: Drehe 90° links...\")\n",
    "        # Rotation\n",
    "        # bot.Move(vx=0, vy=0, omega=omega)\n",
    "        # time.sleep(t_rotate)\n",
    "    \n",
    "    print(\"Quadrat abgeschlossen! Stoppe...\")\n",
    "    # bot.StopMove()\n",
    "\n",
    "# Testen (nur mit verbundenem Roboter!):\n",
    "# drive_square(bot, side_length=2.0, velocity=0.2)\n",
    "\n",
    "print(\"Funktion drive_square() definiert.\")\n",
    "print(\"Unkommentieren zum Ausführen mit echtem Roboter!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2: Geschwindigkeitsramping implementieren\n",
    "\n",
    "**Ziel:** Implementieren Sie eine Funktion, die Geschwindigkeiten smooth interpoliert.\n",
    "\n",
    "**Anforderungen:**\n",
    "- Beschleunigung begrenzen auf max. 1.0 m/s²\n",
    "- Von v=0 auf v=0.6 m/s in ~0.6 Sekunden\n",
    "- Plotten Sie das Geschwindigkeitsprofil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung Aufgabe 2:\n",
    "def smooth_velocity_ramp(v_start, v_target, a_max=1.0, dt=0.1):\n",
    "    \"\"\"\n",
    "    Erzeugt smooth velocity ramp\n",
    "    \"\"\"\n",
    "    velocities = [v_start]\n",
    "    v_current = v_start\n",
    "    \n",
    "    while abs(v_target - v_current) > 0.01:\n",
    "        delta_v = v_target - v_current\n",
    "        max_delta = a_max * dt\n",
    "        \n",
    "        if abs(delta_v) > max_delta:\n",
    "            delta_v = max_delta * np.sign(delta_v)\n",
    "        \n",
    "        v_current += delta_v\n",
    "        velocities.append(v_current)\n",
    "    \n",
    "    return np.array(velocities)\n",
    "\n",
    "# Test:\n",
    "v_profile = smooth_velocity_ramp(v_start=0.0, v_target=0.6, a_max=1.0, dt=0.1)\n",
    "time_steps = np.arange(len(v_profile)) * 0.1\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_steps, v_profile, 'b-o', linewidth=2, markersize=4)\n",
    "plt.xlabel('Zeit [s]')\n",
    "plt.ylabel('Geschwindigkeit [m/s]')\n",
    "plt.title('Smooth Velocity Ramping (a_max = 1.0 m/s²)')\n",
    "plt.grid(True)\n",
    "plt.axhline(y=0.6, color='r', linestyle='--', label='Zielgeschwindigkeit')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Beschleunigungszeit: {time_steps[-1]:.2f} s\")\n",
    "print(f\"Anzahl Steps: {len(v_profile)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3: Figure-8 Trajektorie\n",
    "\n",
    "**Ziel:** Planen Sie eine \"Achter\"-Trajektorie (∞-Form).\n",
    "\n",
    "**Mathematik:**\n",
    "```\n",
    "x(t) = A * sin(ωt)\n",
    "y(t) = A * sin(2ωt) / 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung Aufgabe 3:\n",
    "def figure_eight_trajectory(amplitude=1.0, period=20.0, dt=0.1):\n",
    "    \"\"\"\n",
    "    Erzeugt Figure-8 Trajektorie\n",
    "    \n",
    "    amplitude: Größe der Acht [m]\n",
    "    period: Umlaufzeit [s]\n",
    "    dt: Zeitschritt\n",
    "    \"\"\"\n",
    "    omega = 2 * np.pi / period\n",
    "    t = np.arange(0, period, dt)\n",
    "    \n",
    "    x = amplitude * np.sin(omega * t)\n",
    "    y = amplitude * np.sin(2 * omega * t) / 2\n",
    "    \n",
    "    return x, y, t\n",
    "\n",
    "# Visualisieren:\n",
    "x, y, t = figure_eight_trajectory(amplitude=1.5, period=30.0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y, 'b-', linewidth=2)\n",
    "plt.plot(x[0], y[0], 'go', markersize=10, label='Start')\n",
    "plt.plot(x[-1], y[-1], 'ro', markersize=10, label='Ende')\n",
    "plt.xlabel('X [m]')\n",
    "plt.ylabel('Y [m]')\n",
    "plt.title('Figure-8 Trajektorie')\n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Trajektorie hat {len(x)} Wegpunkte\")\n",
    "print(f\"Gesamtdauer: {t[-1]:.1f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Zusammenfassung Tag 2\n",
    "\n",
    "### Gelernte Konzepte:\n",
    "✓ Dynamisches Gehen & ZMP-Stabilität  \n",
    "✓ Hierarchische Regelungsarchitektur  \n",
    "✓ PID-Kontrolle auf Gelenkebene  \n",
    "✓ Reinforcement Learning für Manipulation  \n",
    "✓ Keyboard-Tele-Operation  \n",
    "✓ Trajektorien-Planung & Geschwindigkeitsprofile  \n",
    "\n",
    "### Wichtige Dateien:\n",
    "- `keyboard_controller.py` - Vollständiges Teleop-System\n",
    "- `g1_arm_rl_env.py` - RL Environment\n",
    "- `train_g1_arm_policy.py` - RL Training Pipeline\n",
    "- `g1_arm_policy_controller.py` - Policy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Hausaufgabe / Vertiefung\n",
    "\n",
    "**Aufgabe 1:** Testen Sie den Keyboard Controller mit echtem Roboter:\n",
    "- Erforschen Sie verschiedene Geschwindigkeitskombinationen\n",
    "- Testen Sie die Turbo-Funktion\n",
    "- Dokumentieren Sie maximale sichere Geschwindigkeiten\n",
    "\n",
    "**Aufgabe 2:** RL Training (optional):\n",
    "```bash\n",
    "cd ../unitree_g1_vibes/RL-shenanigans\n",
    "python3 train_g1_arm_policy.py --algo ppo --total-steps 100000\n",
    "```\n",
    "- Beobachten Sie Training in TensorBoard\n",
    "- Analysieren Sie Reward-Kurven\n",
    "\n",
    "**Aufgabe 3:** Erweiterte Trajektorien:\n",
    "- Implementieren Sie eine Spirale\n",
    "- Kombinieren Sie Vorwärts + Rotation\n",
    "- Visualisieren Sie die Trajektorie\n",
    "\n",
    "**Bonusaufgabe:** Implementieren Sie einen **Joystick-Controller** analog zum Keyboard-Controller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Nächster Tag: Navigation & Umgebungserkennung\n",
    "\n",
    "**Vorschau Tag 3:**\n",
    "- SLAM (Simultaneous Localization and Mapping)\n",
    "- LiDAR-Integration (Livox MID-360)\n",
    "- Globale Pfadplanung (A*, RRT)\n",
    "- Lokale Hindernisvermeidung\n",
    "- Workshop: Navigationsaufgabe mit Hindernisfeld"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
